# Mediflow ETL Pipeline

A complete end-to-end ETL pipeline for healthcare data (**extract â†’ transform â†’ load**) with:

- **Apache Airflow** for orchestration  
- **PostgreSQL** as the target database  
- **Prometheus + Grafana** for monitoring and visualization  
- **Docker Compose** for containerized deployment  

---

## ğŸš€ Quick Start (Local Development)

> Run from the repo root. Tested on Linux / WSL / macOS.

### 1ï¸âƒ£ Setup environment
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

### 2ï¸âƒ£ Prepare data directories
```
mkdir -p data/raw data/processed data/transformed
touch data/raw/.gitkeep data/processed/.gitkeep data/transformed/.gitkeep
```

### 3ï¸âƒ£ Configure environment variables
```
cp .env.example .env
# edit .env with database credentials, SECRET_KEY, etc.
export $(grep -v '^#' .env | xargs)
```

### 4ï¸âƒ£ Start Airflow + Monitoring
```
cd docker/airflow
docker compose up -d
```

### 5ï¸âƒ£ Initialize Airflow database (only first time)
docker compose exec airflow-init airflow db init
docker compose exec airflow-webserver airflow users create \
  --username admin \
  --firstname Admin \
  --lastname User \
  --role Admin \
  --email admin@example.com \
  --password admin

### 6ï¸âƒ£ (Optional) Build ETL images for DockerOperator
```
docker build -t mediflow-extract:latest docker/extract
docker build -t mediflow-transform:latest docker/transform
docker build -t mediflow-load:latest docker/load
```

### ğŸŒ Access Services

Airflow UI â†’ http://localhost:8080
 (login: admin/admin)

Grafana â†’ http://localhost:3000
 (login: admin/admin)

Prometheus â†’ http://localhost:9090

### ğŸ”„ Run ETL Manually (without Airflow)
# 1. Extract
```
python scripts/extract.py
```

# 2. Transform
```
python scripts/transform.py
```

# 3. Load into Postgres
```
python scripts/load.py
```

### ğŸ§ª Running Tests
```
pytest tests/
```

### ğŸ“Š Monitoring Setup

Prometheus scrapes Airflow and system metrics (prometheus.yml config).

Grafana dashboard (airflow_dashboard.json) visualizes:

DAG run stats

Task durations

Success/failure counts

### ğŸ“ Required Files Before Running
.env.example (placeholder secrets) â†’ create your .env file from this.
.gitkeep in data/raw, data/processed, data/transformed to keep dirs in Git.
docker/extract, docker/transform, docker/load (if running ETL via DockerOperator).
docker/airflow/init.sql if initializing DB schema manually.

### âš™ï¸ Troubleshooting
- ** Airflow "database not initialized" â†’ run docker compose exec airflow-init airflow db init.**
- ** Permission denied: /opt/airflow/logs â†’ fix log folder permissions:**
- ** sudo chmod -R 777 docker/airflow/logs**

Prometheus config error â†’ ensure prometheus.yml path is valid in docker-compose.yml.
Grafana no dashboards â†’ ensure grafana/provisioning is mounted correctly.

### ğŸ›¡ï¸ Security Notes

Never commit .env with real credentials.
Use strong values for SECRET_KEY and FERNET_KEY.
For production, store secrets in Vault, AWS Secrets Manager, or Kubernetes Secrets.



ğŸ‘¤ Author
Udit Pandey
Computer Engineering Graduate | Data & Software Projects

---
